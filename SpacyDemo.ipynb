{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# spaCy Demo\n",
    "spaCy is a library for advanced Natural Language Processing in Python and Cython.\n",
    "It's built on the very latest research, and was designed from day one to be used in real products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization of a document using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "demo-string\n"
     ]
    }
   ],
   "source": [
    "# We would be separating a general document of string into various tokens\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab) #Creating a blank Tokenizer with just the English vocabulary\n",
    "tokens = tokenizer(\"This is a demo-string\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adding special cases while Tokenizing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gim', 'me', 'that']\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
    "print([w.text for w in nlp(\"gimme that\")])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Getting Parts of Speech using spaCY\n",
    "For this part we will be using **spaCY's pre-trained** model. We will subject a paragraph for tokenization for this purpose.\n",
    "Following is the lise of all UPOS (Universal Parts of Speech) Symbols\n",
    "\n",
    "* ADJ: adjective\n",
    "* ADV: adverb\n",
    "* AUX: auxiliary verb\n",
    "* NOUN: noun\n",
    "* NUM: numeral\n",
    "* PART: particle\n",
    "* PRON: pronoun\n",
    "* PROPN: proper noun\n",
    "* VERB: verb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple : proper noun\n",
      "is : auxiliary verb\n",
      "looking : verb\n",
      "buying : verb\n",
      "U.K. : proper noun\n",
      "startup : noun\n",
      "1 : numeral\n",
      "billion : numeral\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(text)\n",
    "pos_text = {\"ADJ\": \"adjective\", \"ADV\": \"adverb\",\"AUX\": \"auxiliary verb\",\n",
    "            \"NOUN\": \"noun\",\"NUM\": \"numeral\",\"PART\": \"particle\",\n",
    "            \"PRON\": \"pronoun\",\"PROPN\": \"proper noun\",\"VERB\": \"verb\"}\n",
    "for token in doc:\n",
    "    if token.pos_ in pos_text:\n",
    "        print(token.text, pos_text[token.pos_], sep=\" : \")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Named entity recognition\n",
    "spaCy features an extremely fast statistical entity recognition system, that assigns labels to contiguous spans of tokens.\n",
    "The default model identifies a variety of named and numeric entities, including companies, locations, organizations and products. You can add arbitrary classes to the entity recognition system, and update the model with new examples."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google : ORG\n",
      "Microsoft : ORG\n",
      "Bing : ORG\n",
      "$787.6 billion : MONEY\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "text = \"Google surpassed Microsoft's Bing search engine and is now worth $787.6 billion\"\n",
    "doc = nlp(text)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_, sep=\" : \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India:GPE\n",
      "$12 billion:MONEY\n",
      "US:GPE\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "text = \"India currently has a GDP of $12 billion and it aims to overcome US some day\"\n",
    "doc = nlp(text)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_, sep=\" : \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff Bezos : PERSON\n",
      "Amazon : ORG\n",
      "Airports : ORG\n",
      "the J.F.K. International Airport : FAC\n",
      "Amazon : ORG\n",
      "Amazon : ORG\n",
      "15% : PERCENT\n",
      "English : NORP\n",
      "first : ORDINAL\n",
      "22nd August 2019 : DATE\n",
      "10 pm : TIME\n"
     ]
    }
   ],
   "source": [
    "# Example 3\n",
    "text = \"Jeff Bezos is trying to sponsor Amazon in Airports, such as the J.F.K. International Airport.\" \\\n",
    "    \"Amazon is also trying to enter the food market by selling groceries, fruits etc.\" \\\n",
    "    \"Currently Amazon holds 15% of the food market.\" \\\n",
    "    \"This was a part of my report for the English essay.\" \\\n",
    "    \"I got the first prize for submitting this report\" \\\n",
    "    \"The competition was held on 22nd August 2019 and I got the prize by 10 pm\"\n",
    "doc = nlp(text)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_, sep=\" : \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Word Vectors and Cosine Similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 19.702013 True\n",
      "can True 19.43369 True\n",
      "banana True 17.848612 True\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokens = nlp(\"dog can banana\")\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog can 0.086810715\n",
      "dog banana 0.34545124\n",
      "can dog 0.086810715\n",
      "can can 1.0\n",
      "can banana 0.019619917\n",
      "banana dog 0.34545124\n",
      "banana can 0.019619917\n",
      "banana banana 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\lang_tools\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Training a custom model on spaCy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\lang_tools\\Anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Android Pay expands to Canada\" with entities \"[(0, 11, 'PRODUCT'), (23, 30, 'GPE')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "D:\\lang_tools\\Anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Spotify steps up Asia expansion\" with entities \"[(0, 8, 'ORG'), (17, 21, 'LOC')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_data = [\n",
    "    (\"Uber blew through $1 million a week\", {\"entities\" : [(0, 4, 'ORG')]}),\n",
    "    (\"Android Pay expands to Canada\", {\"entities\": [(0, 11, 'PRODUCT'), (23, 30, 'GPE')]}),\n",
    "    (\"Spotify steps up Asia expansion\", {\"entities\":[(0, 8, \"ORG\"), (17, 21, \"LOC\")]}),\n",
    "    (\"Google Maps launches location sharing\",{\"entities\": [(0, 11, \"PRODUCT\")]}),\n",
    "    (\"Google rebrands its business apps\", {\"entities\":[(0, 6, \"ORG\")]}),\n",
    "    (\"look what i found on google!\", {\"entities\":[(21, 27, \"PRODUCT\")]})\n",
    "]\n",
    "\n",
    "blank_model = spacy.blank(\"en\")\n",
    "optimizer = blank_model.begin_training()\n",
    "for i in range(20):\n",
    "    random.shuffle(train_data)\n",
    "    for text, annotations in train_data:\n",
    "        blank_model.update([text], [annotations], sgd=optimizer)\n",
    "\n",
    "# Saving the trained model\n",
    "blank_model.to_disk('//projects//nlp-hands-on//model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Visualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d40dc328d53d4f1abbc0a64550f8ea8f-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-d40dc328d53d4f1abbc0a64550f8ea8f-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-d40dc328d53d4f1abbc0a64550f8ea8f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-d40dc328d53d4f1abbc0a64550f8ea8f-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-d40dc328d53d4f1abbc0a64550f8ea8f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-d40dc328d53d4f1abbc0a64550f8ea8f-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-d40dc328d53d4f1abbc0a64550f8ea8f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n</g>\n</svg></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(\"This is a sentence\")\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}