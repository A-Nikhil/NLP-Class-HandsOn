{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# spaCy Demo\n",
    "spaCy is a library for advanced Natural Language Processing in Python and Cython.\n",
    "It's built on the very latest research, and was designed from day one to be used in real products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization of a document using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "demo-string\n"
     ]
    }
   ],
   "source": [
    "# We would be separating a general document of string into various tokens\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab) #Creating a blank Tokenizer with just the English vocabulary\n",
    "tokens = tokenizer(\"This is a demo-string\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adding special cases while Tokenizing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gim', 'me', 'that']\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
    "print([w.text for w in nlp(\"gimme that\")])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting Parts of Speech using spaCY\n",
    "For this part we will be using **spaCY's pre-trained** model. We will subject a paragraph for tokenization for this purpose.\n",
    "Following is the lise of all UPOS (Universal Parts of Speech) Symbols\n",
    "\n",
    "* ADJ: adjective\n",
    "* ADV: adverb\n",
    "* AUX: auxiliary verb\n",
    "* NOUN: noun\n",
    "* NUM: numeral\n",
    "* PART: particle\n",
    "* PRON: pronoun\n",
    "* PROPN: proper noun\n",
    "* VERB: verb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple : proper noun\n",
      "is : auxiliary verb\n",
      "looking : verb\n",
      "buying : verb\n",
      "U.K. : proper noun\n",
      "startup : noun\n",
      "1 : numeral\n",
      "billion : numeral\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(text)\n",
    "pos_text = {\"ADJ\": \"adjective\", \"ADV\": \"adverb\",\"AUX\": \"auxiliary verb\",\n",
    "            \"NOUN\": \"noun\",\"NUM\": \"numeral\",\"PART\": \"particle\",\n",
    "            \"PRON\": \"pronoun\",\"PROPN\": \"proper noun\",\"VERB\": \"verb\"}\n",
    "for token in doc:\n",
    "    if token.pos_ in pos_text:\n",
    "        print(token.text, pos_text[token.pos_], sep=\" : \")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Named entity recognition\n",
    "spaCy features an extremely fast statistical entity recognition system, that assigns labels to contiguous spans of tokens.\n",
    "The default model identifies a variety of named and numeric entities, including companies, locations, organizations and products. You can add arbitrary classes to the entity recognition system, and update the model with new examples."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google : ORG\n",
      "Microsoft : ORG\n",
      "Bing : ORG\n",
      "$787.6 billion : MONEY\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "text = \"Google surpassed Microsoft's Bing search engine and is now worth $787.6 billion\"\n",
    "doc = nlp(text)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_, sep=\" : \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India:GPE\n",
      "$12 billion:MONEY\n",
      "US:GPE\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "text = \"India currently has a GDP of $12 billion and it aims to overcome US some day\"\n",
    "doc = nlp(text)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_, sep=\" : \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff Bezos : PERSON\n",
      "Amazon : ORG\n",
      "Airports : ORG\n",
      "the J.F.K. International Airport : FAC\n",
      "Amazon : ORG\n",
      "Amazon : ORG\n",
      "15% : PERCENT\n",
      "English : NORP\n",
      "first : ORDINAL\n",
      "22nd August 2019 : DATE\n",
      "10 pm : TIME\n"
     ]
    }
   ],
   "source": [
    "# Example 3\n",
    "text = \"Jeff Bezos is trying to sponsor Amazon in Airports, such as the J.F.K. International Airport.\" \\\n",
    "    \"Amazon is also trying to enter the food market by selling groceries, fruits etc.\" \\\n",
    "    \"Currently Amazon holds 15% of the food market.\" \\\n",
    "    \"This was a part of my report for the English essay.\" \\\n",
    "    \"I got the first prize for submitting this report\" \\\n",
    "    \"The competition was held on 22nd August 2019 and I got the prize by 10 pm\"\n",
    "doc = nlp(text)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_, sep=\" : \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-bb6defe261a8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mspacy\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdisplacy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mnlp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspacy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"en_core_web_sm\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mdoc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnlp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"This is a sentence\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mdisplacy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstyle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"dep\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(\"This is a sentence\")\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}